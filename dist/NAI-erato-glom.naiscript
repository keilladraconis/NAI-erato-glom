/*---
compatibilityVersion: naiscript-1.0
id: be2503ca-d1b1-45c6-b2eb-06ba375ac1d8
name: Erato-GLoM
version: 0.0.0
createdAt: 1770915596
author: keilladraconis
description: "Erato-GLoM - Two great tastes that taste great together! License: MIT"
memoryLimit: 8
updatedAt: 1770929932
config: []
---*/

/**
 * Erato-GLoM
 * Built with NovelAI Script Build System
 */

(async () => {
    // ─── Config ────────────────────────────────────────────────────────
    const GLM_MODEL = 'glm-4-6';
    const GLM_MAX_TOKENS = 300;
    const DEFAULT_PROMPT = `You are a creative writing consultant reviewing a story in progress. Your job is to produce a short directive (2-4 sentences) that will guide the story's next few paragraphs.

Focus on:
- Preventing repetitive loops or stalling
- Advancing the plot or deepening character dynamics
- Suggesting concrete sensory details, emotional beats, or rising tension
- Maintaining consistency with established characters and setting

Your output will be inserted directly into the story as an instruction block. Write ONLY the directive, nothing else. Use second person ("you") if the story is in second person, otherwise match the story's POV. Be specific and vivid, not generic.`;
    // Storage keys (story:-prefixed for per-story persistence)
    const SK_ENABLED = 'story:glom-enabled';
    const SK_INTERVAL = 'story:glom-interval';
    const SK_PROMPT = 'story:glom-prompt';
    // ─── State ─────────────────────────────────────────────────────────
    let genCount = 0;
    let instructionSectionId = null;
    let consulting = false;
    let glmSignal = null;
    // Initialize defaults if not yet set
    await api.v1.storyStorage.setIfAbsent('glom-enabled', true);
    await api.v1.storyStorage.setIfAbsent('glom-interval', 4);
    await api.v1.storyStorage.setIfAbsent('glom-prompt', DEFAULT_PROMPT);
    // ─── Permissions ───────────────────────────────────────────────────
    const hasDocEdit = await api.v1.permissions.request('documentEdit', 'GLoM inserts and removes instruction paragraphs to guide the story.');
    // ─── Instruction Management ────────────────────────────────────────
    async function removeInstruction() {
        if (instructionSectionId === null)
            return;
        try {
            await api.v1.document.removeParagraph(instructionSectionId);
        }
        catch (_) { /* already gone */ }
        instructionSectionId = null;
    }
    async function insertInstruction(text) {
        if (!hasDocEdit)
            return;
        await removeInstruction();
        const ids = await api.v1.document.sectionIds();
        if (ids.length < 1)
            return;
        if (ids.length >= 2) {
            await api.v1.document.insertParagraphAfter(ids[ids.length - 2], {
                text,
                source: 'instruction',
            });
        }
        else {
            await api.v1.document.insertParagraphAfter(0, {
                text,
                source: 'instruction',
            });
        }
        const newIds = await api.v1.document.sectionIds();
        instructionSectionId = newIds.length >= 2
            ? newIds[newIds.length - 2]
            : newIds[0];
    }
    // ─── GLM Consultation ─────────────────────────────────────────────
    async function consultGLM() {
        if (consulting)
            return;
        consulting = true;
        try {
            // Build the full story context (includes lorebook, memory, AN, etc.)
            // suppressScriptHooks: 'all' prevents side effects from other scripts
            const storyContext = await api.v1.buildContext({
                suppressScriptHooks: 'all',
            });
            if (!storyContext.length)
                return;
            // Read the user's system prompt
            const systemPrompt = await api.v1.storyStorage.get('glom-prompt') || DEFAULT_PROMPT;
            // Assemble messages with static content first for cache efficiency:
            //   1. System prompt (static — always cached after first call)
            //   2. Story context (stable head, volatile tail — older parts cached)
            //   3. Instruction (short, always fresh)
            const messages = [
                { role: 'system', content: systemPrompt },
                ...storyContext,
                { role: 'user', content: 'Write your directive for the next few paragraphs.' },
            ];
            const signal = await api.v1.createCancellationSignal();
            glmSignal = signal;
            const response = await api.v1.generate(messages, {
                model: GLM_MODEL,
                max_tokens: GLM_MAX_TOKENS,
                temperature: 0.7,
            }, undefined, undefined, signal);
            glmSignal = null;
            const guidance = response.choices[0]?.text?.trim();
            if (guidance) {
                await insertInstruction(`[ ${guidance} ]`);
            }
        }
        catch (err) {
            if (glmSignal) {
                glmSignal = null;
            }
            else {
                api.v1.error('GLM consultation failed:', err);
            }
        }
        finally {
            glmSignal = null;
            consulting = false;
        }
    }
    // ─── UI ────────────────────────────────────────────────────────────
    await api.v1.ui.register([
        {
            type: 'scriptPanel',
            id: 'eg-panel',
            name: 'GLoM',
            content: [
                {
                    type: 'row',
                    content: [
                        {
                            type: 'checkboxInput',
                            id: 'glom-enabled',
                            label: 'Enable',
                            storageKey: SK_ENABLED,
                            initialValue: true,
                            onChange: async (enabled) => {
                                if (!enabled)
                                    await removeInstruction();
                            },
                        },
                        {
                            type: 'button',
                            text: 'GLoM',
                            iconId: 'heart',
                            callback: consultGLM,
                            disabledWhileCallbackRunning: true,
                        },
                    ],
                },
                {
                    type: 'sliderInput',
                    id: 'glom-interval',
                    label: 'Consultation interval',
                    storageKey: SK_INTERVAL,
                    min: 1,
                    max: 10,
                    step: 1,
                    initialValue: 4,
                    suffix: ' gens',
                },
                {
                    type: 'collapsibleSection',
                    title: 'System Prompt',
                    initialCollapsed: true,
                    storageKey: SK_PROMPT + '-collapsed',
                    content: [
                        {
                            type: 'multilineTextInput',
                            id: 'glom-prompt',
                            storageKey: SK_PROMPT,
                            initialValue: DEFAULT_PROMPT,
                            placeholder: 'Enter system prompt for GLM...',
                            style: { minHeight: '200px' },
                        },
                    ],
                },
            ],
        },
    ]);
    // ─── Hooks ─────────────────────────────────────────────────────────
    api.v1.hooks.register('onGenerationEnd', async (params) => {
        if (params.model === GLM_MODEL)
            return;
        const enabled = await api.v1.storyStorage.get('glom-enabled');
        if (!enabled)
            return;
        const interval = (await api.v1.storyStorage.get('glom-interval')) || 4;
        genCount++;
        if (genCount >= interval) {
            genCount = 0;
            await consultGLM();
        }
    });
})();
